{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7047b223",
   "metadata": {},
   "source": [
    "# Function Description: MultipleLinearRegression\n",
    "\n",
    "This function performs multiple linear regression and makes predictions based on the model, taking a Pandas DataFrame as input (with the dependent variable as the last column) and returning another Pandas DataFrame as output.\n",
    "\n",
    "## Input Parameters\n",
    "\n",
    "- df (pandas.DataFrame): the input dataframe.\n",
    "\n",
    "\n",
    "- opt (bool): a boolean flag to indicate whether or not to optimize the model (default=False).\n",
    "\n",
    "\n",
    "## Dependencies\n",
    "\n",
    "This function requires the Pandas, NumPy, Scipy and sfrancia libraries to be installed.\n",
    "\n",
    "## Function Steps\n",
    "\n",
    "**1.** The function starts by importing the required libraries, including a custom function for testing the normality of residuals.\n",
    "\n",
    "**2.** It then defines a nested function to check for multicollinearity among the independent variables, excluding columns with perfect correlation to other columns in the DataFrame.\n",
    "\n",
    "**3.** The function calculates the number of observations and variables in the input DataFrame, splitting the predictor and dependent variables, and computing the covariance matrix of the independent variables.\n",
    "\n",
    "**4.** It obtains the coefficients and intercept of the linear regression model by solving the normal equation and prints them.\n",
    "\n",
    "**5.** The function calculates the fitted values and R² of the model, and performs an F-test to check the overall significance of the model. If the F-test is significant, the function then performs a series of T-tests to check the significance of each individual predictor variable.\n",
    "\n",
    "**6.** If the opt parameter of the function is set to True and any of the predictor variables are not significant, the function drops those variables and performs the regression again recursively until all predictor variables are significant or until the maximum number of iterations is reached.\n",
    "\n",
    "**7.** Finally, the function returns a DataFrame with the original input variables and a new column for predicted values based on the linear regression model.\n",
    "\n",
    "\n",
    "### Additional Details\n",
    "\n",
    "\n",
    "- The function checks for multicollinearity among the independent variables by calculating the correlation matrix and excluding columns with perfect correlation (i.e., correlation coefficient of 1).\n",
    "\n",
    "- The function obtains the coefficients and intercept of the linear regression model by solving the normal equation, which involves inverting a matrix. In practice, this can be computationally intensive for large datasets with many variables.\n",
    "\n",
    "- The function checks the normality and heteroscedasticity of the residuals using the Shapiro-Francia test and the Breusch-Pagan test, respectively. If the residuals are not normal or heteroscedastic, the function may not be appropriate for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dec5e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultipleLinearRegression(df, opt=False, it=0):\n",
    "    \n",
    "    '''\n",
    "    This takes a Pandas DataFrame as input (requires that the column corresponding to the dependent variable be the\n",
    "    last column of the DataFrame) and returns another Pandas DataFrame as output, performing multiple linear regression\n",
    "    and making predictions based on the model. It needs the Pandas, NumPy and Scipy Libraries installed.\n",
    "    \n",
    "    The function starts by calculating the number of observations and variables in the input DataFrame,\n",
    "    splitting the predictor and dependent variables, and computing the covariance matrix of the independent variables.\n",
    "    It then obtains the coefficients and intercept of the linear regression model by solving the normal equation,\n",
    "    and prints the intercept and coefficients.\n",
    "\n",
    "    Next, the function calculates the fitted values and R² of the model, and performs an F-test to check the overall\n",
    "    significance of the model. If the F-test is significant, the function then performs a series of T-tests to check the\n",
    "    significance of each individual predictor variable.\n",
    "\n",
    "    If the \"opt\" parameter of the function is set to True and any of the predictor variables are not significant,\n",
    "    the function drops those variables and performs the regression again recursively until all predictor variables\n",
    "    are significant or until the maximum number of iterations is reached.\n",
    "\n",
    "    Finally, the function returns a DataFrame with the original input variables and a new column for predicted values based\n",
    "    on the linear regression model.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): input dataframe\n",
    "        opt (bool): whether or not to optimize the model\n",
    "        \n",
    "    '''\n",
    "    # Importing needed libraries\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from scipy import stats\n",
    "    from sfrancia import shapiroFrancia\n",
    "    \n",
    "    # Fuction for Multicollinearity Analysis\n",
    "    def multicollinearity_analysis(df):\n",
    "        \n",
    "        '''This function aims to exclude columns with perfect correlation to other columns in the DataFrame.'''\n",
    "    \n",
    "        # Correlation Matrix\n",
    "        df_cor = df.corr()\n",
    "\n",
    "        # Getting columns with perfect correlation\n",
    "        perfect_correlation_columns = []\n",
    "        for col in df_cor.columns:\n",
    "            for row in df_cor.index:\n",
    "                if col != row:\n",
    "                    if df_cor[col].loc[row] == 1:\n",
    "                        if set([col, row]) not in perfect_correlation_columns:\n",
    "                            perfect_correlation_columns.append(tuple(set([col, row])))\n",
    "                            \n",
    "        # Excluding columns                    \n",
    "        for tuple_col in list(set(perfect_correlation_columns)):\n",
    "            if tuple_col[0] in df:\n",
    "                print(f'The \"{tuple_col[0]}\" column will be deleted for having a perfect correlation with {tuple_col[1]}.\\n')\n",
    "                df = df.drop(tuple_col[0], 1)\n",
    "                      \n",
    "        # Returning treated Dataframe\n",
    "        return df\n",
    "    \n",
    "    # Function to get Intercept and Coefficients\n",
    "    def get_intercept_and_coef(df):\n",
    "        \n",
    "        ''' This function finds the intercept and coefficients values based on the covariance matrix.'''\n",
    "        \n",
    "        # Getting the Matrix Shape\n",
    "        N, p = df.shape\n",
    "        \n",
    "        # Computing the covariance matrix\n",
    "        df_cov = pd.DataFrame(np.cov(df.values.T, ddof=1))\n",
    "        df_cov = df_cov.drop(df_cov.index.max())\n",
    "        \n",
    "        # Extracting A and b matrices\n",
    "        A = df_cov.iloc[:, 0:p-1].values.astype(float)\n",
    "        b = df_cov.iloc[:,p-1].values.astype(float)\n",
    "        \n",
    "        # Solving for the coefficients\n",
    "        coef = np.linalg.solve(A,b)\n",
    "        \n",
    "        # Computing the intercept\n",
    "        intercept = df.mean()[len(df.mean())-1]\n",
    "        for i in range(0, p-1):\n",
    "            intercept -= df.mean()[i] * coef[i]\n",
    "          \n",
    "        # Returning the intercept and coefficients\n",
    "        return intercept, coef\n",
    "    \n",
    "    # Function for measure the Coefficients statistical significance of the coefficients\n",
    "    def ttest(x_v, N, p, soma_quad_fitted_real, intercept, coef):\n",
    "        \n",
    "        '''Calculates the statistical significance of the coefficients in a multiple linear regression model.'''\n",
    "        \n",
    "        # Getting the degrees of freedom\n",
    "        dof2 = N - p\n",
    "        \n",
    "        # Initialize lists to store results\n",
    "        list_stat_t = []\n",
    "        list_pval = []\n",
    "        list_significance = []\n",
    "        list_std_error = []\n",
    "        \n",
    "        # Add intercept term to predictor variable array\n",
    "        X_ = np.concatenate((np.array([1 for x in range(0, len(df))]).reshape(-1,1), x_v), axis=1)\n",
    "        \n",
    "        # Calculate variance of the regression coefficients\n",
    "        sigma_squared_hat = soma_quad_fitted_real / (N - p)\n",
    "        var_beta_hat = np.linalg.inv(X_.T @ X_) * sigma_squared_hat\n",
    "\n",
    "        # Calculate T statistic and P-value for the intercept term\n",
    "        list_std_error.append(var_beta_hat[0, 0] ** 0.5)\n",
    "        estat_t_alpha = intercept/(var_beta_hat[0, 0] ** 0.5)\n",
    "        pvalt = stats.t.cdf(-abs(estat_t_alpha), dof2) * 2\n",
    "        if pvalt < 0.05:\n",
    "            list_significance.append('y')\n",
    "        else:\n",
    "             list_significance.append('n') \n",
    "        list_stat_t.append(estat_t_alpha)\n",
    "        list_pval.append(stats.t.cdf(-abs(estat_t_alpha), dof2) * 2)\n",
    "        \n",
    "        # Calculate T statistic, P-value, and standard error for each predictor variable\n",
    "        for i in range(0,p-1):\n",
    "            estat_t_beta = coef[i]/(var_beta_hat[i+1, i+1] ** 0.5 )  \n",
    "            list_std_error.append(var_beta_hat[i+1, i+1]** 0.5)\n",
    "            pvalt = stats.t.cdf(-abs(estat_t_beta), dof2) * 2\n",
    "            list_stat_t.append(estat_t_beta)\n",
    "            list_pval.append(stats.t.cdf(-abs(estat_t_beta), dof2) * 2)\n",
    "            if pvalt < 0.05:\n",
    "                list_significance.append('y')\n",
    "            else:\n",
    "                list_significance.append('n')\n",
    "        \n",
    "        # Returning lists\n",
    "        return list_std_error, list_stat_t, list_pval, list_significance\n",
    "    \n",
    "    def breusch_pagan_test(res, yhat):\n",
    "        \n",
    "        '''Perform the Breusch-Pagan Test for Heteroskedasticity.'''\n",
    "        \n",
    "        # Creating a DataFrame for the Breusch-Pagan Test\n",
    "        df_bp = pd.DataFrame({'yhat':yhat, 'resid':res}) \n",
    "        \n",
    "        # Adding the 'up' column\n",
    "        df_bp['up'] = (np.square(df_bp.resid))/np.sum(((np.square(df_bp.resid))/df_bp.shape[0]))\n",
    "        \n",
    "        # Changing the value of p for get the correct intercept and coef\n",
    "        p = 1\n",
    "        intercept_bp, coef_bp = get_intercept_and_coef(df_bp[['yhat', 'up']])\n",
    "        \n",
    "        # Getting the fitted values of the model and the SQReg\n",
    "        fitted_values_bp = (df_bp['yhat'].values*coef_bp[0]) + intercept_bp\n",
    "        soma_quad_fitted_med_bp = ((np.array(fitted_values_bp)-df_bp['up'].mean())**2).sum()\n",
    "        \n",
    "        # Getting Chisquare Statistic\n",
    "        chisq = soma_quad_fitted_med_bp/2\n",
    "        \n",
    "        # Printing and returning the results\n",
    "        print('Breusch Pagan Test for Heteroskedasticity.\\n')\n",
    "        print(f'Chi2: {round(chisq, 4)},\\t p-value: {round(stats.chi2.sf(chisq, 1),4)}')\n",
    "        \n",
    "        if stats.chi2.sf(chisq, 1) < 0.05:\n",
    "            print('\\nThe data shows evidence of heteroskedasticity.')\n",
    "        else:\n",
    "            print('\\nThe data does not show evidence of heteroskedasticity.')\n",
    "        return\n",
    "        \n",
    "    # Check input types\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError(\"df must be a pandas DataFrame.\")\n",
    "    if not isinstance(opt, bool):\n",
    "        raise TypeError(\"opt must be a boolean.\")\n",
    "    if not isinstance(it, int):\n",
    "        raise TypeError(\"it must be an integer.\")\n",
    "     \n",
    "    # Checking Null Values\n",
    "    null_vals = df.isna().sum()\n",
    "    if len(null_vals.loc[null_vals>0].index) > 0:\n",
    "        print(f'NaN values in the columns: {null_vals.loc[null_vals>0].index}')\n",
    "        return\n",
    "     \n",
    "    # Initializing the Informative DataFrame\n",
    "    df_info = pd.DataFrame(index=['Intercept'])\n",
    "    \n",
    "    # Excluding columns with perfect correlation\n",
    "    df = multicollinearity_analysis(df)  \n",
    "    \n",
    "    # Intormative DataFrame\n",
    "    df_info = pd.DataFrame(index=['intercept'] + list(df.columns[0:-1]), columns=['Estimate', 'Std. Error', 'T statistic', 'P value', 'Sig. at 0.05'])\n",
    "    \n",
    "    # DataFrame's Shape\n",
    "    N, p = df.shape\n",
    "    \n",
    "    # Getting Intercept and Coefficients\n",
    "    intercept, coef = get_intercept_and_coef(df)\n",
    "    \n",
    "    # Splitting predictor and dependent\n",
    "    x_v = np.array(df.iloc[:, 0:p-1])\n",
    "    y_v = np.array(df.iloc[:, p-1])\n",
    "    \n",
    "    # Fitted Values\n",
    "    fitted_values = (x_v@coef) + intercept\n",
    "    \n",
    "    # Getting R²\n",
    "    residuals = y_v - np.array(fitted_values)\n",
    "    soma_quad_fitted_med = ((fitted_values-y_v.mean())**2).sum()\n",
    "    soma_quad_fitted_real = (residuals**2).sum()\n",
    "    R = soma_quad_fitted_med / (soma_quad_fitted_med + soma_quad_fitted_real)\n",
    "    \n",
    "    # T-Test\n",
    "    list_pval = ttest(x_v, N, p, soma_quad_fitted_real, intercept, coef)\n",
    "    \n",
    "    # Filling the Informative DataFrame\n",
    "    df_info['Estimate'].loc['intercept'] = intercept\n",
    "    df_info['Estimate'][1:] = coef\n",
    "    df_info[['Std. Error', 'T statistic', 'P value', 'Sig. at 0.05']] = pd.DataFrame(ttest(x_v, N, p, soma_quad_fitted_real, intercept, coef)).T.values\n",
    "    \n",
    "    # Printing the model's overall information\n",
    "    print(f'R²: {round(R,4)},\\tThe Dataframe has {N} registers and {p} columns.\\n')\n",
    "    print(f'F-statistic: {round((soma_quad_fitted_med/(p - 1))/(soma_quad_fitted_real/(N - p)),4)},\\tp-value (F-statistic): {round((1-stats.f.cdf((soma_quad_fitted_med/(p - 1))/(soma_quad_fitted_real/(N - p)), p - 1, N - p)),5)}\\n______________________________________________________________________\\n')\n",
    "        \n",
    "    # If there's any p-value smaller than 0.05 and the parameter opt == True the function will drop non significant variables\n",
    "    if opt == True and max(df_info['P value'][1:]) > 0.05:\n",
    "        print(df_info)\n",
    "        print('\\n______________________________________________________________________\\nExcluding columns not statistically significants.')\n",
    "        max_index = df_info['P value'].loc[(df_info['P value'] == max(df_info[df_info.index != 'intercept']['P value'])) & (df_info.index != 'intercept')].index[0]\n",
    "        it +=1\n",
    "        print(f'Excluded column: {max_index}')\n",
    "        df = df.drop(max_index,1)\n",
    "        print(f'______________________________________________________________________\\n######################################################################')\n",
    "        print(f'\\t\\t\\tIteration number {it}')\n",
    "        print(f'n#####################################################################\\n______________________________________________________________________\\n')\n",
    "        df = MultipleLinearRegression(df, it=it, opt=True)\n",
    "        return df\n",
    "        \n",
    "    # Returning the original Dataframe with the predicted values\n",
    "    else:  \n",
    "        print(df_info)\n",
    "        print('\\n______________________________________________________________________\\n')\n",
    "        df_final = df\n",
    "        df_final['fitted_values'] = intercept \n",
    "        for i in range(0, len(coef)):\n",
    "            df_final['fitted_values'] += df_final[df_final.columns[i]] * coef[i]\n",
    "        \n",
    "        # Testing the normality of the residuals\n",
    "        if len(df) < 31:\n",
    "            # Shapiro-Wilk Test\n",
    "            stat_shap, p_shap = stats.shapiro(residuals)\n",
    "            \n",
    "            # Printing Results\n",
    "            print('Testing the residuals normality using the Shapiro-Wilk test.')\n",
    "            print(f'\\nW: {round(stat_shap,4)},\\t p-value: {round(p_shap,4)}')\n",
    "        else:\n",
    "            # Shapiro-Francia Test\n",
    "            stat_shap, p_shap = shapiroFrancia(residuals)['statistics W'], shapiroFrancia(residuals)['p-value']\n",
    "            \n",
    "            # Printing Results\n",
    "            print('Testing the residuals normality using the Shapiro-Francia test.')\n",
    "            print(f'\\nW: {round(stat_shap,4)},\\t p-value: {round(p_shap,4)}')\n",
    "        if p_shap < 0.05:\n",
    "            print(f'\\nThe residuals do not follow a Normal Distribution.\\n______________________________________________________________________\\n')\n",
    "        else:\n",
    "            print(f'\\nThe residuals do follow a Normal Distribution.\\n______________________________________________________________________\\n')\n",
    "        \n",
    "        # Applying the Breusch Pagan test for Heteroskedasticity\n",
    "        breusch_pagan_test(residuals, fitted_values)\n",
    "        \n",
    "        # Returning the DataFrame with the predicted values\n",
    "        return df_final"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
